{"cells":[{"cell_type":"markdown","metadata":{"id":"o-_ZGM9F7vKj"},"source":["Author: Zhengyong Chen"]},{"cell_type":"markdown","metadata":{"id":"ac--9L7W-UYK"},"source":["### Baseline\n","This is the notebook that train the pharse/passage spolier data on base bert.\n","Most of the model and api are come from hugging face. The following tutorial give us some help.\n","https://huggingface.co/docs/transformers/tasks/question_answering"]},{"cell_type":"markdown","metadata":{"id":"F6mfTN8I4_WK"},"source":["### Environment"]},{"cell_type":"markdown","metadata":{"id":"O83rME25-JHj"},"source":["Download the need libiary"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"uqRtIe-oY-v0","outputId":"2fe66008-c2b4-4ee9-c10f-bfb59f253713"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.0.0+cu118)\n","Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.5.3)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.29.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert-score) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.27.1)\n","Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.65.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score) (23.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert-score) (2022.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.0.0->bert-score) (16.0.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.14.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2022.10.31)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.13.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.4)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score) (3.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers>=3.0.0->bert-score) (2023.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n","Installing collected packages: bert-score\n","Successfully installed bert-score-0.3.13\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Collecting aiohttp (from datasets)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Collecting responses<0.19 (from datasets)\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting accelerate\n","  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->accelerate) (16.0.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.19.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting evaluate\n","  Downloading evaluate-0.4.0-py3-none-any.whl (81 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.14.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n","Installing collected packages: evaluate\n","Successfully installed evaluate-0.4.0\n"]}],"source":["!pip install transformers\n","!pip install bert-score\n","!pip install datasets\n","!pip install accelerate\n","!pip install evaluate"]},{"cell_type":"markdown","metadata":{"id":"w8UaJn6T_IAm"},"source":["Mount to the drive "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sek5n-HVUMJh"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"tTH8fNVe_uyq"},"source":["Set the random seeds for reproducibility."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oBeVWwmS8clr"},"outputs":[],"source":["import torch\n","print(torch.cuda.get_device_name(0))\n","SEED = 1234\n","\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"markdown","metadata":{"id":"0m5R28s8LAN9"},"source":["Set the device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EkXkH2vGK_et"},"outputs":[],"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"UWNV2wUt8xSj"},"source":["Set you model. you can use \n","\n","*   bert-base-cased\n","*   bert-base-uncased\n","*   bert-large-uncased\n","*   bert-large-cased\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lvlEFEyE8wp-"},"outputs":[],"source":["model_name=\"bert-base-cased\""]},{"cell_type":"markdown","metadata":{"id":"fjRpVbTGHWD7"},"source":["Set which type of data you want to train\n","*   'phrase'\n","*   'passage'\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qWorE0VHVQQ"},"outputs":[],"source":["type_of_data='phrase'"]},{"cell_type":"markdown","metadata":{"id":"ZbcBWSdZAGam"},"source":["### Data Preprocessing\n","Get the training file and validation_file from the local directory. Please check path is correct"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5SHoyS0PFRMm"},"outputs":[],"source":["# Set the path to your traning and validation JSONL file\n","training_file = \"/content/gdrive/MyDrive/cse_635/group_project/data/train.jsonl\"\n","validation_file=\"/content/gdrive/MyDrive/cse_635/group_project/data/validation.jsonl\""]},{"cell_type":"markdown","metadata":{"id":"rydqmlpIAUZ2"},"source":["A function that get the start index and end index of each answer from each content of each entry. Also, concatenate sentence array into one big string."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2WKm_oFsFVku"},"outputs":[],"source":["def getanswers(strs ,position):\n","    nums=position[0][0]\n","    start=0\n","    for i in range(len(strs)):\n","      if nums==i:\n","        start+=position[0][1]\n","        break\n","      start+=len(strs[i])\n","      \n","    return ''.join(strs),start"]},{"cell_type":"markdown","metadata":{"id":"DT9D9OPgBJPS"},"source":["A dataset class that read the file through the path, extract data from the file. It just store the question, context, answer and index of answer for each entry. The 'type' parameter is to make the class know which type of data it only load. In this case, passage or phrase."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3teMnQxwJ93S"},"outputs":[],"source":["import json\n","from torch.utils.data import Dataset, DataLoader\n","\n","class MyDataset(Dataset):\n","    def __init__(self, filepath, type):\n","        self.data = []\n","        self.max_length=0\n","        self.id=0\n","        with open(filepath, 'r') as f:\n","            for line in f:\n","                json_obj = json.loads(line)\n","                if json_obj['tags'][0]==type:\n","                    question = json_obj['postText'][0]\n","                    context = json_obj['targetParagraphs']\n","                    answer = json_obj['spoiler']\n","                    strs,start=getanswers(context,json_obj['spoilerPositions'][0])\n","                    context=strs\n","                    extracted_data = {\n","                        'answers': {'answer_start': [start], 'text': answer},\n","                        'context': context,\n","                        'question': question,\n","                        'id':str(self.id),\n","                    }\n","                    self.data.append(extracted_data)\n","                    self.max_length=max(self.max_length,len(context)+len(question[0]))\n","                self.id+=1\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]"]},{"cell_type":"markdown","metadata":{"id":"LFGkC0PfCcoN"},"source":["Load the dataset using the MyDataset just defined"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9qxXSQPiCHeB"},"outputs":[],"source":["training = MyDataset(training_file,type_of_data)\n","validation = MyDataset(validation_file,type_of_data)"]},{"cell_type":"markdown","metadata":{"id":"nXgfr1NfXnYP"},"source":["Check how the data stored "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1684032664874,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"974rIvTYXwUK","outputId":"3a3110a2-0ee0-4dd0-a55e-471946bd795a"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'answers': {'answer_start': [0], 'text': ['2070']}, 'context': '2070 is shaping up to be a great year for Mother Earth.That\\'s when NASA scientists are predicting the hole in the ozone layer might finally make a full recovery. Researchers announced their conclusion, in addition to other findings, in a presentation Wednesday during the annual American Geophysical Union meeting in San Francisco.The team of scientists specifically looked at the chemical composition of the ozone hole, which has shifted in both size and depth since the passing of the Montreal Protocol in 1987. The agreement banned its 197 signatory countries from using chemicals, like chlorofluorocarbons (CFCs), that break down into chlorine in the upper atmosphere and harm the ozone layer.They found that, while levels of chlorine in the atmosphere have indeed decreased as a result of the protocol, it\\'s too soon to tie them to a healthier ozone layer.\"Ozone holes with smaller areas and a larger total amount of ozone are not necessarily evidence of recovery attributable to the expected chlorine decline,\" Susan Strahan of NASA\\'s Goddard Space Flight Center explained in a media briefing. \"That assumption is like trying to understand what\\'s wrong with your car\\'s engine without lifting the hood.\"Instead, the scientists believe the most recent ozone hole changes, including both the largest hole ever, in 2006, and one of the smallest holes, in 2012, are primarily due to weather. Strong winds have the ability to move ozone in large quantities, effectively blocking the hole some years, while failing to block it in others.\"At the moment, it is winds and temperatures that are really controlling how big [the ozone hole] is,\" Strahan told the BBC.LiveScience reports weather is expected to be the predominant factor in the ozone hole\\'s size until 2025, at which point CFCs will have dropped enough as a result of the Montreal Protocol to become noticeable.By 2070, however, the ozone hole is expected to have made a full recovery.\"It’s not going to be a smooth ride,\" Strahan cautioned the Los Angeles Times. \"There will be some bumps in the road, but overall the trend is downward.\"', 'question': 'NASA sets date for full recovery of ozone hole', 'id': '1'}\n","{'answers': {'answer_start': [669], 'text': ['20%']}, 'context': 'Here’s how much you should be tipping your hairdresserMoreRemembering how much you’re supposed to tip anywhere can be hard — what do current trends dictate? Is there such a thing as too much? And what if you got a discount on the service? But knowing how much to tip your hairdresser has to be one of the more confusing tip scenarios out there, especially if you get your hair done at a salon where more than one person works on your strands.Below, once and for all, is a definitive guide to tipping your hairstylist — and their assistant, shampooist, and everyone in between. Thank us later — no tip necessary.If you need a simple baseline, experts agree that tipping 20% is standard and acceptable at any hair salon. If you’re in a smaller town, 15% may be the norm. You can always ask the receptionist at your salon what’s typical, or ask on the phone when you call to make your appointment.Offering the person who shampoos your hair $3 to $5 is a nice gesture. You can hand the money directly to the shampooist, or give it to the receptionist when you check out and ask them to pass it along.As for your stylist’s assistant, that person is likely in training and may not be making much money, so Michelle Lee, master designer and manager at Salon Eva Michelle in Boston, recommends tipping them between $5 and $20.\"All the assistants are there in training to be stylists, and at many places, a lot are working at minimum wage, so anywhere from $5 to $20 is fine depending on how much they end up doing for the client, or if they have been especially gracious to you,\" she told InStyle.Try to bring cash to tip, if possible. Not every credit card machine will allow you to add a tip, and using cash will make it easier to tip the different people who worked on your mane. And yes, it’s OK to tip even if your hairdresser is the owner of the salon.Also, if your salon offers free bang touch-ups, consider bringing a few dollars to leave as a thank-you gesture. Your stylist will look fondly on you next time you come into the salon.If you’re a woman with shorter hair — meaning you get it cut and/or colored regularly — your stylists will understand if you offer a slightly smaller tip. After all, your annual bill is much higher than a longer-haired client’s.As for tipping on a discounted service: Stylists are split on the issue, with some suggesting a 20% tip on the original price of the service, and others saying a tip of 20% on the discounted rate is fine, since the goal is to get you back into the salon. When in doubt, ask at the front desk!Finally, if you’re unsatisfied with your haircut, communicated what you wanted to your stylist, and talked to them about how to fix it but they refused to make changes, you can definitely lower your tip. If they invite you back for a fix-up cut, though, etiquette expert Peggy Post suggests offering a tip of 15-20%.', 'question': 'Here’s how much you should be tipping your hairdresser', 'id': '2'}\n"]}],"source":["print(training[0])\n","print(validation[0])"]},{"cell_type":"markdown","metadata":{"id":"dAwtP37IBOYJ"},"source":["### Tokenization"]},{"cell_type":"markdown","metadata":{"id":"unlxfOg5Ce69"},"source":["Get the tokenizer from the hugging face. Can use bert-base-cased, bert-base-uncased, bert-large-uncased, bert-large-cased"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTlkOVdgKNMA"},"outputs":[],"source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"markdown","metadata":{"id":"IbQA3klUxcWZ"},"source":["Convet our dataset to huggingface dataset for preprocess_function() use."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WtuwW-ADxbpO"},"outputs":[],"source":["from datasets import Dataset\n","dset_training = Dataset.from_list(training)\n","dset_training=dset_training.with_format(\"torch\")\n","\n","dset_validation = Dataset.from_list(validation)\n","dset_validation=dset_validation.with_format(\"torch\")"]},{"cell_type":"markdown","metadata":{"id":"rEqzxuq3XcTf"},"source":["Check how the tokenizer tokenize the data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2330,"status":"ok","timestamp":1684032670921,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"2oRPTj9Zir9M","outputId":"bde395cb-4432-4ae2-8e72-d7bb504ea2d8"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'[CLS] NASA sets date for full recovery of ozone hole [SEP] 2070 is shaping up to be a great year for Mother Earth. That\\'s when NASA scientists are predicting the hole in the ozone layer might finally make a full recovery. Researchers announced their conclusion, in addition to other findings, in a presentation Wednesday during the annual American Geophysical Union meeting in San Francisco. The team of scientists specifically looked at the chemical composition of the ozone hole, which has shifted in both size and depth since the passing of the Montreal Protocol in 1987. The agreement banned its 197 signatory countries from using chemicals, like chlorofluorocarbons ( CFCs ), that break down into chlorine in the upper atmosphere and harm the ozone layer. They found that, while levels of chlorine in the atmosphere have indeed decreased as a result of the protocol, it\\'s too soon to tie them to a healthier ozone layer. \" Ozone holes with smaller areas and a larger total amount of ozone are not necessarily evidence of recovery attributable to the expected chlorine decline, \" Susan Strahan of NASA\\'s Goddard Space Flight Center explained in a media briefing. \" That assumption is like trying to understand what\\'s wrong with your car\\'s engine without lifting the hood. \" Instead, the scientists believe the most recent ozone hole changes, including both the largest hole ever, in 2006, and one of the smallest holes, in 2012, are primarily due to weather. Strong winds have the ability to move ozone in large quantities, effectively blocking the hole some years, while failing to block it in others. \" At the moment, it is winds and temperatures that are really controlling how big [ the ozone hole ] is, \" Strahan told the BBC. LiveScience reports weather is expected to be the predominant factor in the ozone hole\\'s size until 2025, at which point CFCs will have dropped enough as a result of the Montreal Protocol to become noticeable. By 2070, however, the ozone hole is expected to have made a full recovery. \" It ’ s not going to be a smooth ride, \" Strahan cautioned the Los Angeles Times. \" There will be some bumps in the road, but overall the trend is downward. \" [SEP]'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["context = dset_training[0][\"context\"]\n","question = dset_training[0][\"question\"]\n","\n","inputs = tokenizer(question, context)\n","tokenizer.decode(inputs[\"input_ids\"])"]},{"cell_type":"markdown","metadata":{"id":"OLDEq8JUX79h"},"source":["See how to use return_overflowing_tokens parameter to chunk the long input entry."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1684032670922,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"6sQL1neAnh_l","outputId":"78a21988-ba7f-4f10-bd8f-f0b0fa88540d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[CLS] NASA sets date for full recovery of ozone hole [SEP] 2070 is shaping up to be a great year for Mother Earth. That's when NASA scientists are predicting the hole in the ozone layer might finally make a full recovery. Researchers announced their conclusion, in addition to other findings, in a presentation Wednesday during the annual American Geophysical Union meeting in San Francisco. The team of scientists specifically looked at the chemical composition of the ozone hole, which has shifted in both size and depth since the passing of the Montreal Protocol in 1987. The agreement banned its 197 signatory countries from using chemicals, like chlorofluorocarbons ( CFCs ), that break down into chlorine in the upper atmosphere and harm the ozone layer. They found that, while levels of chlorine in the atmosphere have indeed decreased as a result of the protocol, it's too soon to tie them to a healthier ozone layer. \" Ozone holes with smaller areas and a larger total amount of ozone are not necessarily evidence of recovery attributable to the expected chlorine decline, \" Susan Strahan of NASA's Goddard Space Flight Center explained in a media briefing. \" That assumption is like trying to understand what's wrong with your car's engine without lifting the hood. \" Instead, the scientists believe the most recent ozone hole changes, including both the largest hole ever, in 2006, and one of the smallest holes, in 2012, are primarily due to weather. Strong winds have the ability to move ozone in large quantities, effectively blocking the hole some years, while failing to block it in others. \" At the moment, it is winds and temperatures that are really controlling how big [ the ozone hole ] is, \" Strahan told the BBC. LiveScience reports weather is expected to be the predominant factor [SEP]\n","[CLS] NASA sets date for full recovery of ozone hole [SEP] what's wrong with your car's engine without lifting the hood. \" Instead, the scientists believe the most recent ozone hole changes, including both the largest hole ever, in 2006, and one of the smallest holes, in 2012, are primarily due to weather. Strong winds have the ability to move ozone in large quantities, effectively blocking the hole some years, while failing to block it in others. \" At the moment, it is winds and temperatures that are really controlling how big [ the ozone hole ] is, \" Strahan told the BBC. LiveScience reports weather is expected to be the predominant factor in the ozone hole's size until 2025, at which point CFCs will have dropped enough as a result of the Montreal Protocol to become noticeable. By 2070, however, the ozone hole is expected to have made a full recovery. \" It ’ s not going to be a smooth ride, \" Strahan cautioned the Los Angeles Times. \" There will be some bumps in the road, but overall the trend is downward. \" [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}],"source":["inputs = tokenizer(\n","        question,\n","        context,\n","        max_length=384,\n","        truncation=\"only_second\",\n","        stride=128,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",      \n","    )\n","for ids in inputs[\"input_ids\"]:\n","    print(tokenizer.decode(ids))"]},{"cell_type":"markdown","metadata":{"id":"es2dcFSAC0U6"},"source":["A preprocess function for training. Tokenize each data first. And then create the start and end index of the answer in the context for loss function. If no answer, the start and end index will be zero.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wX8UlKoGKt0N"},"outputs":[],"source":["max_length = 384\n","stride = 128\n","\n","def preprocess_function_training(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","        \n","    )\n","\n","    offset_mapping = inputs.pop(\"offset_mapping\")\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, offset in enumerate(offset_mapping):\n","        sample_idx = sample_map[i]\n","        answer = answers[sample_idx]\n","        start_char = answer[\"answer_start\"][0]\n","        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","        sequence_ids = inputs.sequence_ids(i)\n","\n","        # Find the start and end of the context\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        # If the answer is not fully inside the context, label is (0, 0)\n","        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","        else:\n","            # Otherwise it's the start and end token positions\n","            idx = context_start\n","            while idx <= context_end and offset[idx][0] <= start_char:\n","                idx += 1\n","            start_positions.append(idx - 1)\n","\n","            idx = context_end\n","            while idx >= context_start and offset[idx][1] >= end_char:\n","                idx -= 1\n","            end_positions.append(idx + 1)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs"]},{"cell_type":"markdown","metadata":{"id":"gLDlJ1xPEC3h"},"source":["Use map function and preprocess_function_training as parameter to tokenize our training data for bert used."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4081,"status":"ok","timestamp":1684032674994,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"7xG8EvyVdyeo","outputId":"4349fdbf-9913-47a3-a5d0-05c86f8b6c66"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b999105423848b28cd86ac29cbc52f1","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1367 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_training = dset_training.map(preprocess_function_training, batched=True,remove_columns=dset_training.column_names)"]},{"cell_type":"markdown","metadata":{"id":"TQCE_IkYxpzS"},"source":["A preprocess function for validation. Similiar to preprocess_function_training. Add a example_id that used for evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBie5tVtxw-1"},"outputs":[],"source":["def preprocess_function_validation(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    example_ids = []\n","\n","    for i in range(len(inputs[\"input_ids\"])):\n","        sample_idx = sample_map[i]\n","        example_ids.append(examples[\"id\"][sample_idx])\n","\n","        sequence_ids = inputs.sequence_ids(i)\n","        offset = inputs[\"offset_mapping\"][i]\n","        inputs[\"offset_mapping\"][i] = [\n","            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n","        ]\n","\n","    inputs[\"example_id\"] = example_ids\n","\n","    offset_mapping = inputs[\"offset_mapping\"]\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, offset in enumerate(offset_mapping):\n","        sample_idx = sample_map[i]\n","        answer = answers[sample_idx]\n","        start_char = answer[\"answer_start\"][0]\n","        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","        sequence_ids = inputs.sequence_ids(i)\n","\n","        # Find the start and end of the context\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        # If the answer is not fully inside the context, label is (0, 0)\n","        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","        else:\n","            # Otherwise it's the start and end token positions\n","            idx = context_start\n","            while idx <= context_end and offset[idx][0] <= start_char:\n","                idx += 1\n","            start_positions.append(idx - 1)\n","\n","            idx = context_end\n","            while idx >= context_start and offset[idx][1] >= end_char:\n","                idx -= 1\n","            end_positions.append(idx + 1)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","\n","    return inputs"]},{"cell_type":"markdown","metadata":{"id":"hHPMeULSyF5V"},"source":["Use map function and preprocess_function_validation() as parameter to tokenize our validation data for bert used."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1390,"status":"ok","timestamp":1684032676376,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"6sVFBbpUyANt","outputId":"191912de-5439-48b5-cb21-c7369ba4465a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd162d6d81784166b59bc981e761d4c0","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/335 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_validation = dset_validation.map(preprocess_function_validation, batched=True,remove_columns=dset_validation.column_names)"]},{"cell_type":"markdown","metadata":{"id":"Mo1IGEIvEYHy"},"source":["###Training"]},{"cell_type":"markdown","metadata":{"id":"2A7_UEYgZccU"},"source":["Setting the gpu device, model and output directory. You can save your trained model to your own path by setting variable output_dir."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":188,"referenced_widgets":["1f60faadde334fa89b6667c2d9989d72","3ada0ff7e348436d8d963781309eeb37","71adba7f81cc45809a6114b76c9b501e","49255df665ab45dc971bdc4c14b21c99","f35c9866fa454ae39c2040fc5f2cd22a","19f360e9d84242fa9e824b33472f7205","fb340935a6d74398a901df3100db2db3","5a57a8f6823a40b8a2c4d58413083bfc","e4899e3a66b44ccaa83499dbf7b46528","e7392152eddb44faa741eacc619d0c0b","abed6e5a9c9247c1a8cb0f0ac8d91067"]},"executionInfo":{"elapsed":11617,"status":"ok","timestamp":1684030582149,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"MzPQovj24WmZ","outputId":"4a3eb03b-888a-4710-ab14-16016ab29053"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f60faadde334fa89b6667c2d9989d72","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForQuestionAnswering\n","\n","model = BertForQuestionAnswering.from_pretrained('bert-base-cased').to(device)\n","output_dir=\"/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase\""]},{"cell_type":"markdown","metadata":{"id":"G2Hgu2Nra91f"},"source":["Setting some hyper paramater for fine tuning.\n","Decrease the per_device_train_batch_size and per_device_eval_batch_size if you have the memory in training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ojr5QlLh3RZo"},"outputs":[],"source":["from transformers import TrainingArguments,Trainer\n","\n","args = TrainingArguments(\n","    output_dir=output_dir,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    logging_strategy=\"epoch\",\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    learning_rate=2e-5,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    fp16=True,\n",")"]},{"cell_type":"markdown","metadata":{"id":"vB5aTq5CbB70"},"source":["Start training"]},{"cell_type":"markdown","metadata":{"id":"G0whi0rpbH5Y"},"source":["As we can see, the validation loss increase at epoch 3. Therefore, we will use the model checkpoint at eopch 2 for our evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":531,"status":"error","timestamp":1684030835894,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"77u1T1ExV_3y","outputId":"288eddcf-50ea-4f1a-dffd-e09dc349d225"},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">629</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_config_dict</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">626 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">627 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">628 │   │   │   │   # Load from local folder or from cache or download from model Hub and ca</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>629 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>resolved_config_file = cached_file(                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">630 │   │   │   │   │   </span>pretrained_model_name_or_path,                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">631 │   │   │   │   │   </span>configuration_file,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">632 │   │   │   │   │   </span>cache_dir=cache_dir,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hub.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">417</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cached_file</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 414 │   </span>user_agent = http_user_agent(user_agent)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 415 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 416 │   │   # Load from URL or cache if already cached</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 417 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>resolved_file = hf_hub_download(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 418 │   │   │   </span>path_or_repo_id,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 419 │   │   │   </span>filename,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 420 │   │   │   </span>subfolder=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(subfolder) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> subfolder,                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">112</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_fn</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">109 │   │   │   </span>kwargs.items(),  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Kwargs values</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   │   </span>):                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> arg_name <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> [<span style=\"color: #808000; text-decoration-color: #808000\">\"repo_id\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"from_id\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"to_id\"</span>]:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>112 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>validate_repo_id(arg_value)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> arg_name == <span style=\"color: #808000; text-decoration-color: #808000\">\"token\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> arg_value <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   │   │   │   </span>has_token = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_validators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">160</span> in              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">validate_repo_id</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> HFValidationError(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Repo id must be a string, not {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(repo_id)<span style=\"color: #808000; text-decoration-color: #808000\">}: '{</span>repo_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> repo_id.count(<span style=\"color: #808000; text-decoration-color: #808000\">\"/\"</span>) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>160 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> HFValidationError(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" '{</span>repo_id<span style=\"color: #808000; text-decoration-color: #808000\">}'. Use `repo_type` argument if needed.\"</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">HFValidationError: </span>Repo id must be in the form <span style=\"color: #008000; text-decoration-color: #008000\">'repo_name'</span> or <span style=\"color: #008000; text-decoration-color: #008000\">'namespace/repo_name'</span>: \n","<span style=\"color: #008000; text-decoration-color: #008000\">'/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase/checkpoint-414'</span>. Use `repo_type` \n","argument if needed.\n","\n","<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n","\n","<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 1&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2251</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2248 │   │   # Load config if we don't provide a configuration</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2249 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(config, PretrainedConfig):                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2250 │   │   │   </span>config_path = config <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> config <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> pretrained_model_name_or_pat  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2251 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>config, model_kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.config_class.from_pretrained(                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2252 │   │   │   │   </span>config_path,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2253 │   │   │   │   </span>cache_dir=cache_dir,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2254 │   │   │   │   </span>return_unused_kwargs=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">547</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">from_pretrained</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">544 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">assert config.output_attentions == True</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">545 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">assert unused_kwargs == {\"foo\": False}</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">546 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">```\"\"\"</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>547 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_dict, kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>.get_config_dict(pretrained_model_name_or_path, **kwarg   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">548 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"model_type\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">hasattr</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"model_type\"</span>) <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"m</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">549 │   │   │   </span>logger.warning(                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">550 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"You are using a model of type {</span>config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">'model_type'</span>]<span style=\"color: #808000; text-decoration-color: #808000\">} to instantia</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">574</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_config_dict</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">571 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">572 │   │   </span>original_kwargs = copy.deepcopy(kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">573 │   │   # Get config dict associated with the base config file</span>                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>574 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config_dict, kwargs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>._get_config_dict(pretrained_model_name_or_path, **kwar   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">575 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> config_dict:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">576 │   │   │   </span>original_kwargs[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>] = config_dict[<span style=\"color: #808000; text-decoration-color: #808000\">\"_commit_hash\"</span>]                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">577 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">configuration_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">650</span> in               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_config_dict</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">647 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">648 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>:                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">649 │   │   │   │   # For any other exception, we throw a generic error.</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>650 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">EnvironmentError</span>(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">651 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"Can't load the configuration of '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}'.</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">652 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" from 'https://huggingface.co/models', make sure you don't have a l</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">653 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\" name. Otherwise, make sure '{</span>pretrained_model_name_or_path<span style=\"color: #808000; text-decoration-color: #808000\">}' is t</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span>Can't load the configuration of \n","<span style=\"color: #008000; text-decoration-color: #008000\">'/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase/checkpoint-414'</span>. If you were trying \n","to load it from <span style=\"color: #008000; text-decoration-color: #008000\">'https://huggingface.co/models'</span>, make sure you don't have a local directory with the same name. \n","Otherwise, make sure <span style=\"color: #008000; text-decoration-color: #008000\">'/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase/checkpoint-414'</span> \n","is the correct path to a directory containing a config.json file\n","</pre>\n"],"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m629\u001b[0m in               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92m_get_config_dict\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m626 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m627 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m628 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Load from local folder or from cache or download from model Hub and ca\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m629 \u001b[2m│   │   │   │   \u001b[0mresolved_config_file = cached_file(                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m630 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mpretrained_model_name_or_path,                                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m631 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconfiguration_file,                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m632 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mcache_dir=cache_dir,                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/utils/\u001b[0m\u001b[1;33mhub.py\u001b[0m:\u001b[94m417\u001b[0m in \u001b[92mcached_file\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 414 \u001b[0m\u001b[2m│   \u001b[0muser_agent = http_user_agent(user_agent)                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 415 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 416 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load from URL or cache if already cached\u001b[0m                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 417 \u001b[2m│   │   \u001b[0mresolved_file = hf_hub_download(                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 418 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_repo_id,                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 419 \u001b[0m\u001b[2m│   │   │   \u001b[0mfilename,                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 420 \u001b[0m\u001b[2m│   │   │   \u001b[0msubfolder=\u001b[94mNone\u001b[0m \u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(subfolder) == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m subfolder,                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m112\u001b[0m in \u001b[92m_inner_fn\u001b[0m    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m109 \u001b[0m\u001b[2m│   │   │   \u001b[0mkwargs.items(),  \u001b[2m# Kwargs values\u001b[0m                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   \u001b[0m):                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m arg_name \u001b[95min\u001b[0m [\u001b[33m\"\u001b[0m\u001b[33mrepo_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mfrom_id\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mto_id\u001b[0m\u001b[33m\"\u001b[0m]:                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m112 \u001b[2m│   │   │   │   \u001b[0mvalidate_repo_id(arg_value)                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melif\u001b[0m arg_name == \u001b[33m\"\u001b[0m\u001b[33mtoken\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mand\u001b[0m arg_value \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhas_token = \u001b[94mTrue\u001b[0m                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/\u001b[0m\u001b[1;33m_validators.py\u001b[0m:\u001b[94m160\u001b[0m in              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mvalidate_repo_id\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must be a string, not \u001b[0m\u001b[33m{\u001b[0m\u001b[96mtype\u001b[0m(repo_id)\u001b[33m}\u001b[0m\u001b[33m: \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m repo_id.count(\u001b[33m\"\u001b[0m\u001b[33m/\u001b[0m\u001b[33m\"\u001b[0m) > \u001b[94m1\u001b[0m:                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m160 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m HFValidationError(                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mRepo id must be in the form \u001b[0m\u001b[33m'\u001b[0m\u001b[33mrepo_name\u001b[0m\u001b[33m'\u001b[0m\u001b[33m or \u001b[0m\u001b[33m'\u001b[0m\u001b[33mnamespace/repo_name\u001b[0m\u001b[33m'\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\"\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mrepo_id\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m. Use `repo_type` argument if needed.\u001b[0m\u001b[33m\"\u001b[0m                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mHFValidationError: \u001b[0mRepo id must be in the form \u001b[32m'repo_name'\u001b[0m or \u001b[32m'namespace/repo_name'\u001b[0m: \n","\u001b[32m'/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase/checkpoint-414'\u001b[0m. Use `repo_type` \n","argument if needed.\n","\n","\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n","\n","\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 1>\u001b[0m:\u001b[94m1\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m2251\u001b[0m in \u001b[92mfrom_pretrained\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2248 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load config if we don't provide a configuration\u001b[0m                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2249 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(config, PretrainedConfig):                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2250 \u001b[0m\u001b[2m│   │   │   \u001b[0mconfig_path = config \u001b[94mif\u001b[0m config \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m pretrained_model_name_or_pat  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2251 \u001b[2m│   │   │   \u001b[0mconfig, model_kwargs = \u001b[96mcls\u001b[0m.config_class.from_pretrained(                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2252 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mconfig_path,                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2253 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcache_dir=cache_dir,                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2254 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mreturn_unused_kwargs=\u001b[94mTrue\u001b[0m,                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m547\u001b[0m in               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mfrom_pretrained\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m544 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33massert config.output_attentions == True\u001b[0m                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m545 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33massert unused_kwargs == {\"foo\": False}\u001b[0m                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m546 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m```\"\"\"\u001b[0m                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m547 \u001b[2m│   │   \u001b[0mconfig_dict, kwargs = \u001b[96mcls\u001b[0m.get_config_dict(pretrained_model_name_or_path, **kwarg   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m548 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mmodel_type\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict \u001b[95mand\u001b[0m \u001b[96mhasattr\u001b[0m(\u001b[96mcls\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mmodel_type\u001b[0m\u001b[33m\"\u001b[0m) \u001b[95mand\u001b[0m config_dict[\u001b[33m\"\u001b[0m\u001b[33mm\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m549 \u001b[0m\u001b[2m│   │   │   \u001b[0mlogger.warning(                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m550 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mYou are using a model of type \u001b[0m\u001b[33m{\u001b[0mconfig_dict[\u001b[33m'\u001b[0m\u001b[33mmodel_type\u001b[0m\u001b[33m'\u001b[0m]\u001b[33m}\u001b[0m\u001b[33m to instantia\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m574\u001b[0m in               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92mget_config_dict\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m571 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m572 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_kwargs = copy.deepcopy(kwargs)                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m573 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Get config dict associated with the base config file\u001b[0m                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m574 \u001b[2m│   │   \u001b[0mconfig_dict, kwargs = \u001b[96mcls\u001b[0m._get_config_dict(pretrained_model_name_or_path, **kwar   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m575 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m config_dict:                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m576 \u001b[0m\u001b[2m│   │   │   \u001b[0moriginal_kwargs[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m] = config_dict[\u001b[33m\"\u001b[0m\u001b[33m_commit_hash\u001b[0m\u001b[33m\"\u001b[0m]                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m577 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mconfiguration_utils.py\u001b[0m:\u001b[94m650\u001b[0m in               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92m_get_config_dict\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m647 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m648 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m649 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# For any other exception, we throw a generic error.\u001b[0m                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m650 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mEnvironmentError\u001b[0m(                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m651 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCan\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt load the configuration of \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m.\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m652 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m from \u001b[0m\u001b[33m'\u001b[0m\u001b[33mhttps://huggingface.co/models\u001b[0m\u001b[33m'\u001b[0m\u001b[33m, make sure you don\u001b[0m\u001b[33m'\u001b[0m\u001b[33mt have a l\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m653 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m name. Otherwise, make sure \u001b[0m\u001b[33m'\u001b[0m\u001b[33m{\u001b[0mpretrained_model_name_or_path\u001b[33m}\u001b[0m\u001b[33m'\u001b[0m\u001b[33m is t\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mOSError: \u001b[0mCan't load the configuration of \n","\u001b[32m'/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase/checkpoint-414'\u001b[0m. If you were trying \n","to load it from \u001b[32m'https://huggingface.co/models'\u001b[0m, make sure you don't have a local directory with the same name. \n","Otherwise, make sure \u001b[32m'/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase/checkpoint-414'\u001b[0m \n","is the correct path to a directory containing a config.json file\n"]},"metadata":{},"output_type":"display_data"}],"source":["best_checkpoint = BertForQuestionAnswering.from_pretrained(\"/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase/checkpoint-414\")\n","checkpoint_tokenizer=AutoTokenizer.from_pretrained(\"/content/gdrive/MyDrive/cse_635/individual_project/code/baseline/bert_phrase/checkpoint-414\")\n","trainer_best_checkpoint = Trainer(\n","    model=best_checkpoint,\n","    args=args,\n","    train_dataset=tokenized_training,\n","    eval_dataset=tokenized_validation,\n","    tokenizer=checkpoint_tokenizer,\n",")"]},{"cell_type":"markdown","metadata":{"id":"pA7QUTm7bb7Z"},"source":["###Evaluation"]},{"cell_type":"markdown","metadata":{"id":"GJjf5MpZZxTO"},"source":["Create bleu, meteor, bertscore class by using huggingface interface"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1233,"status":"ok","timestamp":1684032746971,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"MZaTxYT477DI","outputId":"9d23cbf8-a9eb-46c4-a208-e30a1fe7e89e"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["import evaluate\n","\n","bleu = evaluate.load('bleu')\n","meteor = evaluate.load('meteor')\n","bertscore=evaluate.load('bertscore')"]},{"cell_type":"markdown","metadata":{"id":"LbmBWXdjGM-l"},"source":["Set the model_dir to your trained model.\n","\n"," Due to the memory size of the google drive, we lost all the models. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1565,"status":"ok","timestamp":1684032779658,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"PHIce_npF6Wf","outputId":"3fefbbb6-e3a0-49cc-8bc8-f9800be2e1ee"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForQuestionAnswering: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import BertForQuestionAnswering,Trainer\n","model_dir=model_name #The path of the trained model.\n","best_checkpoint = BertForQuestionAnswering.from_pretrained(model_dir).to(device)\n","checkpoint_tokenizer=AutoTokenizer.from_pretrained(model_dir)\n","trainer_best_checkpoint = Trainer(\n","    model=best_checkpoint,\n","    train_dataset=tokenized_training,\n","    eval_dataset=tokenized_validation,\n","    tokenizer=checkpoint_tokenizer,\n",")"]},{"cell_type":"markdown","metadata":{"id":"CLsCwO9tZ_wg"},"source":["A function that for evaluation use. For each entry, get the 20 best answer according to the logit and then choose the best one that has the logit score.\n","Then use the evalutation function above to calcualte the scores."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125,"status":"ok","timestamp":1684032886707,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"km5DrzKV-rHd","outputId":"b9cbc3b4-ff36-404a-c013-f0c70aee1985"},"outputs":[{"name":"stdout","output_type":"stream","text":["There maximum lenght of predicted answer is 8\n"]}],"source":["from tqdm.auto import tqdm\n","import collections\n","import numpy as np\n","n_best = 20\n","if type_of_data=='phrase':\n","  max_answer_length=8\n","else:\n","  max_answer_length=50\n","print(\"There maximum lenght of predicted answer is \"+str(max_answer_length))\n","\n","def compute_metrics(start_logits, end_logits, features, examples):\n","    example_to_features = collections.defaultdict(list)\n","    for idx, feature in enumerate(features):\n","        example_to_features[feature[\"example_id\"]].append(idx)\n","    predicted_answers = []\n","    for example in tqdm(examples):\n","        example_id = example[\"id\"]\n","        context = example[\"context\"]\n","        answers = []\n","        # Loop through all features associated with that example\n","        for feature_index in example_to_features[example_id]:\n","            start_logit = start_logits[feature_index]\n","            end_logit = end_logits[feature_index]\n","            offsets = features[feature_index][\"offset_mapping\"]\n","\n","            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n","            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    # Skip answers that are not fully in the context\n","                    if offsets[start_index] is None or offsets[end_index] is None:\n","                        continue\n","                    # Skip answers with a length that is either < 0 or > max_answer_length\n","                    if (\n","                        end_index < start_index\n","                        or end_index - start_index + 1 > max_answer_length\n","                    ):\n","                        continue\n","                    answer = {\n","                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n","                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n","                    }\n","                    answers.append(answer)\n","        # Select the answer with the best score\n","        if len(answers) > 0:\n","            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n","            predicted_answers.append(best_answer[\"text\"])\n","        else:\n","            predicted_answers.append(\"\")\n","    \n","    print(predicted_answers[0:20])\n","    theoretical_answers = [ex[\"answers\"][\"text\"][0] for ex in examples]\n","    print(theoretical_answers[0:20])\n","    bleu_score=bleu.compute(predictions=predicted_answers, references=theoretical_answers)\n","    meteor_score=meteor.compute(predictions=predicted_answers, references=theoretical_answers)\n","    bertscore_score=bertscore.compute(predictions=predicted_answers, references=theoretical_answers,lang=\"en\",model_type=\"distilbert-base-uncased\")\n","    return bleu_score,meteor_score,bertscore_score"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178,"referenced_widgets":["329bed9cf5024a62a31a41b4a392d211","5f74e37137904826941c2c929c6351b4","673f1ca2ef6748bd97549f972183d91a","e468de43713045dba4f4fc0a6622ace7","3c1a9cfc43f54bbc8c62e3deb39cec29","3c7c960ef1034681821d186f448acb7b","1d41aa3dcb524b3a83669ac91c9de153","0787061d2d9444c59c9b8ce07d69936b","25ce1cfb3d0a46edbca8edccad07786f","eaf29df69a9141359219dc2b33f5feb3","99e39fbf2d634482a3cd1b584a9f519b"]},"executionInfo":{"elapsed":132414,"status":"ok","timestamp":1684033021725,"user":{"displayName":"陈政庸","userId":"10337584101855109558"},"user_tz":240},"id":"MDg4cAfqew03","outputId":"abbfba8e-2954-4cdb-cd77-53682fb5c653"},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"329bed9cf5024a62a31a41b4a392d211","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/335 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["['and ask them', 'the', 'redients1 t', 'Shima and Mr.', 'Mosquito Control Section', 'Wei', 'who started earlier, supervisors', 'firms iOS 9.3', 'Round', 'ala', 'placed illustrations of cats throughout the', 'Steg', 'to mention Beyon', 'from', 'hosted a sale of Bob and', 'the', 'in the image you see here', 'was part and parcel', 'to endorse Clinton this year', 'ous heap.']\n","['20%', 'Sprite', 'Smoky Paprika-Baked Garbanzo Beans', 'Anthony Bourdain', 'Dibrom', 'They don’t fart', 'starts later', 'bricking iPad Pros', 'Stace Nelson', 'reduced fat sour cream', 'Edward Gorey', 'Rag & Bone', 'pixie cut', 'southern flying squirrel', \"Hope's antique cabinet\", 'August 6th', 'perfectly average', '\"but\"', 'The Arizona Republic', 'apocalyptic omen']\n","{'bleu': 0.0, 'precisions': [0.025919732441471572, 0.003484320557491289, 0.0016286644951140066, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 1.4004683840749415, 'translation_length': 1196, 'reference_length': 854}\n","{'meteor': 0.016875759719428323}\n","bert score: {precision: 0.5517654418945312 recall: 0.5476038455963135 f1: 0.549676775932312}\n"]}],"source":["predictions, _, _ = trainer_best_checkpoint.predict(tokenized_validation)\n","start_logits, end_logits = predictions\n","bl, me, be= compute_metrics(start_logits, end_logits, tokenized_validation, dset_validation)\n","print(bl)\n","print(me)\n","print(\"bert score: {precision: \"+ str(be['precision'][0])+\" recall: \"+str(be['recall'][0])+\" f1: \"+str(be['f1'][0])+\"}\")"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["dAwtP37IBOYJ"],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0787061d2d9444c59c9b8ce07d69936b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19f360e9d84242fa9e824b33472f7205":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d41aa3dcb524b3a83669ac91c9de153":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f60faadde334fa89b6667c2d9989d72":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ada0ff7e348436d8d963781309eeb37","IPY_MODEL_71adba7f81cc45809a6114b76c9b501e","IPY_MODEL_49255df665ab45dc971bdc4c14b21c99"],"layout":"IPY_MODEL_f35c9866fa454ae39c2040fc5f2cd22a"}},"25ce1cfb3d0a46edbca8edccad07786f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"329bed9cf5024a62a31a41b4a392d211":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5f74e37137904826941c2c929c6351b4","IPY_MODEL_673f1ca2ef6748bd97549f972183d91a","IPY_MODEL_e468de43713045dba4f4fc0a6622ace7"],"layout":"IPY_MODEL_3c1a9cfc43f54bbc8c62e3deb39cec29"}},"3ada0ff7e348436d8d963781309eeb37":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19f360e9d84242fa9e824b33472f7205","placeholder":"​","style":"IPY_MODEL_fb340935a6d74398a901df3100db2db3","value":"Downloading pytorch_model.bin: 100%"}},"3c1a9cfc43f54bbc8c62e3deb39cec29":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c7c960ef1034681821d186f448acb7b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49255df665ab45dc971bdc4c14b21c99":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7392152eddb44faa741eacc619d0c0b","placeholder":"​","style":"IPY_MODEL_abed6e5a9c9247c1a8cb0f0ac8d91067","value":" 436M/436M [00:08&lt;00:00, 35.6MB/s]"}},"5a57a8f6823a40b8a2c4d58413083bfc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f74e37137904826941c2c929c6351b4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c7c960ef1034681821d186f448acb7b","placeholder":"​","style":"IPY_MODEL_1d41aa3dcb524b3a83669ac91c9de153","value":"100%"}},"673f1ca2ef6748bd97549f972183d91a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0787061d2d9444c59c9b8ce07d69936b","max":335,"min":0,"orientation":"horizontal","style":"IPY_MODEL_25ce1cfb3d0a46edbca8edccad07786f","value":335}},"71adba7f81cc45809a6114b76c9b501e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a57a8f6823a40b8a2c4d58413083bfc","max":435779157,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e4899e3a66b44ccaa83499dbf7b46528","value":435779157}},"99e39fbf2d634482a3cd1b584a9f519b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abed6e5a9c9247c1a8cb0f0ac8d91067":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e468de43713045dba4f4fc0a6622ace7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eaf29df69a9141359219dc2b33f5feb3","placeholder":"​","style":"IPY_MODEL_99e39fbf2d634482a3cd1b584a9f519b","value":" 335/335 [00:52&lt;00:00,  5.24it/s]"}},"e4899e3a66b44ccaa83499dbf7b46528":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e7392152eddb44faa741eacc619d0c0b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eaf29df69a9141359219dc2b33f5feb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f35c9866fa454ae39c2040fc5f2cd22a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb340935a6d74398a901df3100db2db3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}